#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿå¼€å§‹ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•åœ¨å®é™…é¡¹ç›®ä¸­ä½¿ç”¨ç®€åŒ–ç‰ˆæ–‡æ¡£æ ¡éªŒæ¨¡å—
"""

from simple_document_validator import SimpleDocumentValidator
import json

def main():
    print("ğŸš€ ç®€åŒ–ç‰ˆæ–‡æ¡£æ ¡éªŒæ¨¡å— - å¿«é€Ÿå¼€å§‹ç¤ºä¾‹")
    print("=" * 50)
    
    # æ­¥éª¤1ï¼šåˆ›å»ºéªŒè¯å™¨å¹¶åŠ è½½æ¨¡æ¿
    print("\nğŸ“‹ æ­¥éª¤1ï¼šåŠ è½½æ–‡æ¡£æ¨¡æ¿")
    validator = SimpleDocumentValidator("simple_template_example.py")
    
    if not validator.main_model:
        print("âŒ æ¨¡æ¿åŠ è½½å¤±è´¥")
        return
    
    print(f"âœ… æ¨¡æ¿åŠ è½½æˆåŠŸ: {validator.main_model.__name__}")
    
    # æ­¥éª¤2ï¼šå‡†å¤‡è¦éªŒè¯çš„æ–‡æ¡£æ•°æ®
    print("\nğŸ“„ æ­¥éª¤2ï¼šå‡†å¤‡æ–‡æ¡£æ•°æ®")
    document_data = {
        "id": "example_doc_001",
        "title": "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ç ”ç©¶",
        "document_type": "ç ”ç©¶",
        "summary": "æœ¬æ–‡æ¢è®¨äº†äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨åŒ»ç–—è¯Šæ–­ã€è¯ç‰©ç ”å‘ç­‰é¢†åŸŸçš„æœ€æ–°åº”ç”¨è¿›å±•ã€‚",
        "author": {
            "name": "ç‹åŒ»ç”Ÿ",
            "affiliation": "åŒ—äº¬å¤§å­¦åŒ»å­¦é™¢",
            "email": "wang.doctor@pku.edu.cn"
        },
        "paragraphs": [
            {
                "content": "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨é©å‘½æ€§åœ°æ”¹å˜åŒ»ç–—è¡Œä¸šçš„è¯Šæ–­å’Œæ²»ç–—æ–¹å¼ã€‚",
                "page_number": 1,
                "sentiment_score": 0.8,
                "keywords": ["äººå·¥æ™ºèƒ½", "åŒ»ç–—", "è¯Šæ–­"]
            },
            {
                "content": "æ·±åº¦å­¦ä¹ ç®—æ³•åœ¨åŒ»å­¦å½±åƒåˆ†æä¸­å±•ç°å‡ºäº†è¶…è¶Šäººç±»ä¸“å®¶çš„å‡†ç¡®æ€§ã€‚",
                "page_number": 2,
                "sentiment_score": 0.9,
                "keywords": ["æ·±åº¦å­¦ä¹ ", "åŒ»å­¦å½±åƒ", "å‡†ç¡®æ€§"]
            }
        ],
        "tags": ["äººå·¥æ™ºèƒ½", "åŒ»ç–—", "ç ”ç©¶"],
        "created_at": "2024-01-20T15:30:00Z",
        "word_count": 2500
    }
    
    print("ğŸ“ æ–‡æ¡£æ•°æ®å‡†å¤‡å®Œæˆ")
    
    # æ­¥éª¤3ï¼šéªŒè¯æ–‡æ¡£
    print("\nğŸ” æ­¥éª¤3ï¼šéªŒè¯æ–‡æ¡£ç»“æ„")
    validation_result = validator.validate_document(document_data)
    
    if validation_result["valid"]:
        print("âœ… æ–‡æ¡£éªŒè¯é€šè¿‡")
    else:
        print("âŒ æ–‡æ¡£éªŒè¯å¤±è´¥:")
        for error in validation_result["errors"][:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé”™è¯¯
            print(f"   - {error['loc']}: {error['msg']}")
        return
    
    # æ­¥éª¤4ï¼šæå–æ ‡æ³¨å­—æ®µ
    print("\nğŸ“Š æ­¥éª¤4ï¼šæå–æ ‡æ³¨å­—æ®µ")
    annotations = validator.extract_annotations(document_data)
    
    print("æå–åˆ°çš„æ ‡æ³¨å­—æ®µ:")
    for path, value in annotations.items():
        if isinstance(value, list):
            if len(value) <= 3:  # çŸ­åˆ—è¡¨ç›´æ¥æ˜¾ç¤º
                print(f"   {path}: {value}")
            else:  # é•¿åˆ—è¡¨æ˜¾ç¤ºå‰å‡ ä¸ª
                print(f"   {path}: {value[:2]}... (å…±{len(value)}é¡¹)")
        elif isinstance(value, str) and len(value) > 50:
            print(f"   {path}: {value[:47]}...")
        else:
            print(f"   {path}: {value}")
    
    print(f"\nğŸ“ˆ æ€»å…±æå–äº† {len(annotations)} ä¸ªæ ‡æ³¨å­—æ®µ")
    
    # æ­¥éª¤5ï¼šè·å–å­—æ®µæ¨¡å¼ä¿¡æ¯
    print("\nğŸ“‹ æ­¥éª¤5ï¼šæŸ¥çœ‹å­—æ®µæ¨¡å¼")
    schema = validator.get_annotation_schema()
    
    print("æ ‡æ³¨å­—æ®µæ¨¡å¼æ¦‚è§ˆ:")
    required_fields = [f for f in schema if f['required']]
    optional_fields = [f for f in schema if not f['required']]
    
    print(f"   å¿…å¡«å­—æ®µ: {len(required_fields)} ä¸ª")
    print(f"   å¯é€‰å­—æ®µ: {len(optional_fields)} ä¸ª")
    
    # æ˜¾ç¤ºå‡ ä¸ªé‡è¦å­—æ®µçš„è¯¦ç»†ä¿¡æ¯
    important_fields = ["title", "author.name", "paragraphs[].content"]
    print("\né‡è¦å­—æ®µè¯¦æƒ…:")
    for field in schema:
        if field['path'] in important_fields:
            print(f"   ğŸ“Œ {field['path']}")
            print(f"      ç±»å‹: {field['type']}")
            print(f"      å¿…éœ€: {'æ˜¯' if field['required'] else 'å¦'}")
            print(f"      æè¿°: {field['description']}")
            if field['constraints']:
                print(f"      çº¦æŸ: {field['constraints']}")
            print()
    
    # æ­¥éª¤6ï¼šå®é™…åº”ç”¨åœºæ™¯æ¼”ç¤º
    print("ğŸ¯ æ­¥éª¤6ï¼šå®é™…åº”ç”¨åœºæ™¯æ¼”ç¤º")
    
    # åœºæ™¯1ï¼šæ‰¹é‡éªŒè¯å¤šä¸ªæ–‡æ¡£
    print("\nåœºæ™¯1ï¼šæ‰¹é‡éªŒè¯æ–‡æ¡£")
    documents = [document_data]  # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šæ˜¯å¤šä¸ªæ–‡æ¡£
    
    valid_count = 0
    for i, doc in enumerate(documents, 1):
        result = validator.validate_document(doc)
        if result["valid"]:
            valid_count += 1
            print(f"   æ–‡æ¡£ {i}: âœ… é€šè¿‡")
        else:
            print(f"   æ–‡æ¡£ {i}: âŒ å¤±è´¥")
    
    print(f"   æ‰¹é‡éªŒè¯ç»“æœ: {valid_count}/{len(documents)} é€šè¿‡")
    
    # åœºæ™¯2ï¼šæ•°æ®è´¨é‡æ£€æŸ¥
    print("\nåœºæ™¯2ï¼šæ•°æ®è´¨é‡æ£€æŸ¥")
    quality_issues = []
    
    # æ£€æŸ¥æ ‡é¢˜é•¿åº¦
    title = annotations.get("title", "")
    if len(title) < 10:
        quality_issues.append("æ ‡é¢˜è¿‡çŸ­ï¼Œå»ºè®®å¢åŠ æè¿°æ€§å†…å®¹")
    
    # æ£€æŸ¥æ®µè½æ•°é‡
    paragraphs = annotations.get("paragraphs[].content", [])
    if len(paragraphs) < 2:
        quality_issues.append("æ®µè½æ•°é‡è¾ƒå°‘ï¼Œå»ºè®®å¢åŠ å†…å®¹")
    
    # æ£€æŸ¥å…³é”®è¯
    all_keywords = annotations.get("paragraphs[].keywords", [])
    total_keywords = sum(len(kw_list) for kw_list in all_keywords)
    if total_keywords < 5:
        quality_issues.append("å…³é”®è¯æ•°é‡è¾ƒå°‘ï¼Œå»ºè®®å¢åŠ æ›´å¤šå…³é”®è¯")
    
    if quality_issues:
        print("   å‘ç°çš„è´¨é‡é—®é¢˜:")
        for issue in quality_issues:
            print(f"   âš ï¸  {issue}")
    else:
        print("   âœ… æ•°æ®è´¨é‡è‰¯å¥½")
    
    # åœºæ™¯3ï¼šç”Ÿæˆæ•°æ®æŠ¥å‘Š
    print("\nåœºæ™¯3ï¼šç”Ÿæˆæ•°æ®æŠ¥å‘Š")
    report = {
        "document_id": document_data["id"],
        "validation_status": "é€šè¿‡" if validation_result["valid"] else "å¤±è´¥",
        "annotation_count": len(annotations),
        "quality_score": max(0, 100 - len(quality_issues) * 20),  # ç®€å•çš„è´¨é‡è¯„åˆ†
        "extracted_data": {
            "title": annotations.get("title"),
            "author": annotations.get("author.name"),
            "paragraph_count": len(annotations.get("paragraphs[].content", [])),
            "keyword_count": sum(len(kw) for kw in annotations.get("paragraphs[].keywords", []))
        }
    }
    
    print("   ğŸ“Š æ•°æ®æŠ¥å‘Š:")
    for key, value in report.items():
        if key == "extracted_data":
            print(f"   {key}:")
            for sub_key, sub_value in value.items():
                print(f"      {sub_key}: {sub_value}")
        else:
            print(f"   {key}: {value}")
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("   1. åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œå¯ä»¥å°†éªŒè¯å™¨é›†æˆåˆ°æ•°æ®å¤„ç†æµæ°´çº¿ä¸­")
    print("   2. å¯ä»¥æ ¹æ®éªŒè¯ç»“æœè‡ªåŠ¨åˆ†ç±»å’Œå¤„ç†æ–‡æ¡£")
    print("   3. æå–çš„æ ‡æ³¨å­—æ®µå¯ä»¥ç›´æ¥ç”¨äºæœºå™¨å­¦ä¹ è®­ç»ƒ")
    print("   4. å­—æ®µæ¨¡å¼ä¿¡æ¯å¯ä»¥ç”¨äºç”Ÿæˆå‰ç«¯è¡¨å•")

if __name__ == "__main__":
    main() 